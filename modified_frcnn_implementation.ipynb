{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bridal-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "#irr\n",
    "import mxnet \n",
    "from mxnet.gluon import nn\n",
    "from mxnet import gluon, image, np, npx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import os\n",
    "import pandas as pd\n",
    "from d2l import mxnet as d2l\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import init\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passing-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    return npx.gpu(i) if npx.num_gpus() >= i + 1 else npx.cpu()\n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [cpu()] if no GPU exists.\"\"\"\n",
    "    devices = [npx.gpu(i) for i in range(npx.num_gpus())]\n",
    "    return devices if devices else [npx.cpu()]\n",
    "\n",
    "\n",
    "def read_dataset():\n",
    "    \"\"\"read data from file pre known and returns image array, unique image add,name and dict of \n",
    "    {name:bbox list}.\"\"\"\n",
    "    data = pd.read_csv('json_to_csv_with_address.csv')\n",
    "    x=data.loc[:,['image_address','image_name']]\n",
    "    x=x.drop_duplicates()\n",
    "    img_real = [cv2.imread(item) for item in x['image_address']]\n",
    "    img_real = [cv2.cvtColor(item, cv2.COLOR_BGR2RGB) for item in img_real]\n",
    "    \n",
    "    y = data.loc[:,['ymin','xmin','ymax','xmax','label']]\n",
    "    boxes = dict({item:[] for item in x['image_name']})\n",
    "    \n",
    "    for i,name in enumerate(data['image_name']):\n",
    "        boxes[name].append([y.loc[i]])\n",
    "\n",
    "    \n",
    "    return img_real,x, boxes\n",
    "\n",
    "def return_bbox_with_label(x,name):\n",
    "    '''takes input x=dict of {name: bbox}, name= list of unique image names .\n",
    "    and returns bbox , label as list'''\n",
    "    temp = x[name]\n",
    "    lst = []\n",
    "    label = []\n",
    "    for i in temp:\n",
    "        for j in i:\n",
    "            lst.append([j[0],j[1],j[2],j[3]])\n",
    "            label.append(j[4])\n",
    "    return lst,label\n",
    "    \n",
    "def plot_im_box(im,box,label=None):\n",
    "    '''plot boxes on image im and returns plot fig'''\n",
    "    image = im.copy()\n",
    "    color = [(255,0,0),(0,255,0),(0,0,255),(255,255,0),(255,0,255),(0,255,255)]\n",
    "    for j,i in enumerate(box):\n",
    "        thickness= 2\n",
    "\n",
    "        image = cv2.rectangle(image, (int(i[1]),int(i[0])) ,(int(i[3]),int(i[2])), color[j%len(color)], thickness)\n",
    "        if label!=None:\n",
    "            cv2.putText(image, text= label[j], org=(int(i[1]),int(i[0])),\n",
    "                    fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.5, color=(255,255,255),\n",
    "                    thickness=2, lineType=cv2.LINE_AA)\n",
    "    #cv2.imshow(window_name, image)\n",
    "    return plt.imshow(image)\n",
    "\n",
    "def box_iou(boxes1, boxes2):\n",
    "    \"\"\"Compute IOU between two sets of boxes of shape (N,4) and (M,4).\"\"\"\n",
    "    # Compute box areas\n",
    "    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *\n",
    "                              (boxes[:, 3] - boxes[:, 1]))\n",
    "    area1 = box_area(boxes1)\n",
    "    area2 = box_area(boxes2)\n",
    "    lt = np.maximum(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
    "    rb = np.minimum(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]\n",
    "    wh = (rb - lt).clip(min=0)  # [N,M,2]\n",
    "    inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n",
    "    unioun = area1[:, None] + area2 - inter\n",
    "    return inter / unioun\n",
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "    ce = -np.log(y_hat[range(len(y_hat)), y])\n",
    "    return ce.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesser-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = try_gpu()\n",
    "ctx = npx.cpu()\n",
    "all_device = try_all_gpus()\n",
    "\n",
    "data = pd.read_csv('json_to_csv_with_address.csv')\n",
    "z = data['label'].drop_duplicates()\n",
    "label_id = dict({item:i for i,item in enumerate(z)})\n",
    "label_name = []\n",
    "for item in z:\n",
    "    label_name.append(item)\n",
    "num_labels = len(label_name)\n",
    "\n",
    "im,x, b = read_dataset()     #im for image used in cv2.rect, b for dictionary of {image_name:[bbox,label]}, x for df of [locn,im_name]\n",
    "img = np.array(im, dtype= np.float32) #dummy of im\n",
    "\n",
    "model = vision.vgg16(pretrained=True )    #pretrained vgg16 model \n",
    "fe = list(model.features)\n",
    "\n",
    "\n",
    "dummy_img = np.zeros((1,3,800,800), dtype = np.float32)\n",
    "\n",
    "k= np.array(dummy_img , dtype= np.float32)\n",
    "req_features=[]\n",
    "for i in fe:\n",
    "    k= i(k)\n",
    "    if k.shape[2]<800//16:\n",
    "        break\n",
    "    req_features.append(i)\n",
    "    out_channels = k.shape[1]\n",
    "\n",
    "\n",
    "#after res some irr \n",
    "ratios= [0.5,1,2]\n",
    "anchor_scales=[8,16,32]\n",
    "sub_sample = 16 \n",
    "ctr_y = sub_sample/ 2.\n",
    "ctr_x = sub_sample/ 2.\n",
    "\n",
    "fe_size = 800//16\n",
    "sub_sample = 16 \n",
    "ctr_x = np.arange(sub_sample, (fe_size+1)*sub_sample, sub_sample)\n",
    "ctr_y = np.arange(sub_sample, (fe_size+1)*sub_sample, sub_sample)\n",
    "\n",
    "ctr = np.empty((len(ctr_x)*len(ctr_y),2), dtype = np.int32)\n",
    "index = 0 \n",
    "for xx in range(len(ctr_x)):\n",
    "    for yy in range(len(ctr_y)):\n",
    "        ctr[index,1]= ctr_x[xx] - 8\n",
    "        ctr[index,0]= ctr_y[yy] - 8\n",
    "        index +=1\n",
    "\n",
    "        \n",
    "index = 0 \n",
    "anchors = np.zeros(((fe_size*fe_size*9),4))\n",
    "for c in ctr:\n",
    "    ctr_y, ctr_x = c\n",
    "    for i in range(len(ratios)):\n",
    "        for j in range(len(anchor_scales)):\n",
    "            h = sub_sample * anchor_scales[j]* np.sqrt(ratios[i])\n",
    "            w = sub_sample * anchor_scales[j]* np.sqrt(1./ratios[i])\n",
    "            \n",
    "            anchors[index, 0] = ctr_y - h/2\n",
    "            anchors[index, 1] = ctr_x - w/2\n",
    "            anchors[index, 2] = ctr_y + h/2\n",
    "            anchors[index, 3] = ctr_x + w/2\n",
    "            index +=1\n",
    "            \n",
    "anchor_boxes = anchors\n",
    "index_inside = np.where(\n",
    "        (anchor_boxes[:, 0] >= 0) &\n",
    "        (anchor_boxes[:, 1] >= 0) &\n",
    "        (anchor_boxes[:, 2] <= 800) &\n",
    "        (anchor_boxes[:, 3] <= 800)\n",
    "    )[0]\n",
    "valid_anchor_boxes = anchor_boxes[index_inside]\n",
    "\n",
    "anc_height = anchor_boxes[:, 2] - anchor_boxes[:, 0]\n",
    "anc_width = anchor_boxes[:, 3] - anchor_boxes[:, 1]\n",
    "anc_ctr_y = anchor_boxes[:, 0] + 0.5 * anc_height\n",
    "anc_ctr_x = anchor_boxes[:, 1] + 0.5 * anc_width\n",
    "\n",
    "\n",
    "mid_channels = 512\n",
    "in_channels = 512\n",
    "n_anchor = 9\n",
    "\n",
    "conv1 = nn.Conv2D(mid_channels, kernel_size=3, strides=1, padding=1,in_channels=in_channels)\n",
    "reg_layer = nn.Conv2D(n_anchor*4, kernel_size=1, strides = 1, padding=0,activation = 'relu',in_channels=mid_channels)\n",
    "cls_layer = nn.Conv2D(n_anchor*2, kernel_size=1, strides = 1, padding= 0,activation = 'softrelu',in_channels=mid_channels)\n",
    "\n",
    "#conv1\n",
    "conv1.weight.initialize(init.Normal(sigma=0.01))\n",
    "#reg_layer\n",
    "reg_layer.weight.initialize(init.Normal(sigma=0.01))\n",
    "#cls_layer\n",
    "cls_layer.weight.initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "\n",
    "conv1.bias.initialize(init.Zero())\n",
    "reg_layer.bias.initialize(init.Zero())\n",
    "cls_layer.bias.initialize(init.Zero())\n",
    "\n",
    "nms_thresh = 0.7  # non-maximum supression (NMS) \n",
    "n_train_pre_nms = 12000 # no. of train pre-NMS\n",
    "n_train_post_nms = 2000 # after nms, training Fast R-CNN using 2000 RPN proposals\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300 # During testing we evaluate 300 proposals,\n",
    "min_size = 16\n",
    "\n",
    "n_sample = 128  # Number of samples from roi \n",
    "pos_ratio = 0.25 # Number of positive examples out of the n_samples\n",
    "pos_iou_thresh = 0.5  # Min iou of region proposal with any groundtruth object to consider it as positive label\n",
    "neg_iou_thresh_hi = 0.5  # iou 0~0.5 is considered as negative (0, background)\n",
    "neg_iou_thresh_lo = 0.0\n",
    "\n",
    "#final classification\n",
    "roi_head_classifier = nn.Sequential()\n",
    "roi_head_classifier.add(nn.Dense(4096, activation='relu'),\n",
    "                       nn.Dense(4096, activation = 'relu'))\n",
    "roi_head_classifier.collect_params().initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "cls_loc = nn.Dense(10*4, activation= 'relu')\n",
    "cls_loc.weight.initialize(init.Normal(sigma=0.01))\n",
    "cls_loc.bias.initialize(init.Zero())\n",
    "score_l= nn.Dense(10, activation = 'softrelu')\n",
    "score_l.weight.initialize(init.Normal(sigma=0.01))\n",
    "score_l.bias.initialize(init.Zero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sound-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0  #it can be 0 to 130 only  box = list of bbox, l = label of bbox\n",
    "box,l = return_bbox_with_label(b,x['image_name'][x.index[j]])\n",
    "bbox = np.array(box, dtype= np.float32)\n",
    "label_l = l   #list of label names\n",
    "label_s = [label_id[item] for item in l]   #list of label id's\n",
    "labels = np.array(label_s, dtype= np.int32)  #np array of label id's\n",
    "      #1 bit in feature map of out_channels corresponds to 16*16 of raw\n",
    "\n",
    "img0= img[j]\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "#imgTensor= transform(img0)\n",
    "imgTensor = np.expand_dims(transform(img0),axis=0)\n",
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    for x in req_features:\n",
    "        net.add(x)\n",
    "\n",
    "out_map=net(imgTensor)\n",
    "out_map.shape\n",
    "\n",
    "ious = np.zeros((len(valid_anchor_boxes), len(bbox)), dtype=np.float32)\n",
    "ious = box_iou(valid_anchor_boxes,bbox)\n",
    "gt_argmax_ious_row = ious.argmax(axis=0)\n",
    "gt_max_ious = ious[gt_argmax_ious_row, np.arange(ious.shape[1])]\n",
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
    "argmax_ious = ious.argmax(axis=1)\n",
    "max_ious = ious[np.arange(len(index_inside)), argmax_ious]\n",
    "\n",
    "label = np.zeros((len(index_inside), ), dtype=np.int32)-1\n",
    "\n",
    "pos_iou_threshold  = 0.7\n",
    "neg_iou_threshold = 0.3\n",
    "label[gt_argmax_ious] = 1\n",
    "label[max_ious >= pos_iou_threshold] = 1\n",
    "label[max_ious < neg_iou_threshold] = 0\n",
    "\n",
    "n_sample = 256\n",
    "pos_ratio = .5\n",
    "n_pos = int(pos_ratio * n_sample)\n",
    "\n",
    "pos_index = np.where(label == 1)[0]\n",
    "\n",
    "if len(pos_index)>n_pos:\n",
    "    disable_index = np.random.choice(pos_index, \n",
    "                                     size = (len(pos_index) - n_pos), \n",
    "                                     replace = False)\n",
    "    label[disable_index] = -1\n",
    "    \n",
    "    \n",
    "n_neg =int( n_sample * np.sum(label == 1))\n",
    "neg_index =np.where(label==0)[0]\n",
    "#neg_index = np.array(np.where(label == 0), dtype= np.int64).reshape(-1,1)\n",
    "if len(neg_index)> n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size= (len(neg_index) - (n_neg)), replace = False)\n",
    "    label[disable_index]=-1\n",
    "\n",
    "max_iou_bbox = bbox[argmax_ious]      # associativity of anchor to its corresponding ground truth bbox\n",
    "#print(max_iou_bbox.shape)\n",
    "\n",
    "height = valid_anchor_boxes[:,2] - valid_anchor_boxes[:,0]\n",
    "width = valid_anchor_boxes[:,3] - valid_anchor_boxes[:,1]\n",
    "ctr_y = valid_anchor_boxes[:,0]+ 0.5*height\n",
    "ctr_y = valid_anchor_boxes[:,1]+ 0.5*width\n",
    "\n",
    "base_height = max_iou_bbox[:,2] - max_iou_bbox[:,0]\n",
    "base_width = max_iou_bbox[:,3] - max_iou_bbox[:,1]\n",
    "base_ctr_y = max_iou_bbox[:,0] + 0.5*base_height\n",
    "base_ctr_x = max_iou_bbox[:,1] + 0.5*base_width\n",
    "\n",
    "eps = np.finfo(height.dtype).eps\n",
    "\n",
    "height = np.maximum(height, eps)  #done to remove devide by zero error\n",
    "width = np.maximum(width, eps)\n",
    "\n",
    "dy = (base_ctr_y - ctr_y)/ height\n",
    "dx = (base_ctr_x - ctr_x)/ width\n",
    "dh = np.log(base_height/ height)\n",
    "dw = np.log(base_width/ width)\n",
    "\n",
    "anchor_locs = np.vstack((dy,dx,dh,dw))\n",
    "\n",
    "#print(anchor_locs)\n",
    "anchor_locs = anchor_locs.transpose()\n",
    "#print(anchor_locs.shape, anchor_locs)\n",
    "\n",
    "anchor_labels = np.zeros((len(anchors),), dtype = label.dtype)-1\n",
    "anchor_labels[index_inside] = label\n",
    "\n",
    "anchor_locations = np.zeros((len(anchors),anchors.shape[1]), dtype = anchor_locs.dtype)\n",
    "anchor_locations[index_inside,:] = anchor_locs\n",
    "\n",
    "z= conv1(out_map)\n",
    "pred_anchor_locs = reg_layer(z)\n",
    "pred_cls_scores = cls_layer(z)\n",
    "\n",
    "\n",
    "pred_anchor_locs = np.transpose(pred_anchor_locs, (0,2,3,1)). reshape(1,-1,4)\n",
    "pred_cls_scores = np.transpose(pred_cls_scores,(0,2,3,1))\n",
    "objectness_score= pred_cls_scores.reshape(1,50,50,9,2)[:,:,:,:,1].reshape(1,-1)\n",
    "pred_cls_scores= pred_cls_scores.reshape(1,50,50,9,2).reshape(1,-1,2)\n",
    "\n",
    "rpn_loc = pred_anchor_locs[0]\n",
    "rpn_score = pred_cls_scores[0]\n",
    "gt_rpn_loc = anchor_locations\n",
    "gt_rpn_score = anchor_labels\n",
    "\n",
    "#loss start\n",
    "##rpn_cls_loss = cross_entropy( rpn_score,gt_rpn_score)\n",
    "ce_los = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "rpn_cls_loss= ce_los(rpn_score,gt_rpn_score).mean()\n",
    "#loss over\n",
    "\n",
    "pos = (gt_rpn_score>0 ).reshape(-1,1)\n",
    "mask = np.ones((pos.shape[1],4), dtype= pos.dtype)\n",
    "mask = pos * mask\n",
    "\n",
    "mask_loc_preds = rpn_loc[mask].reshape(-1, 4)\n",
    "mask_loc_targets = gt_rpn_loc[mask].reshape(-1, 4)\n",
    "#print(mask_loc_preds.shape, mask_loc_targets.shape)\n",
    "\n",
    "\n",
    "#loss start\n",
    "t = np.abs(mask_loc_targets - mask_loc_preds)\n",
    "rpn_loc_loss = mxnet.nd.npx.smooth_l1(t).sum()\n",
    "\n",
    "rpn_lambda = 10.\n",
    "N_reg = (gt_rpn_score >0).sum()\n",
    "rpn_loc_loss = rpn_loc_loss.sum() / N_reg\n",
    "rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)\n",
    "#loss over\n",
    "\n",
    "pred_anchor_locs_numpy = pred_anchor_locs[0]\n",
    "objectness_score_numpy = objectness_score[0]\n",
    "dy = pred_anchor_locs_numpy[:, 0::4] # dy\n",
    "dx = pred_anchor_locs_numpy[:, 1::4] # dx\n",
    "dh = pred_anchor_locs_numpy[:, 2::4] # dh\n",
    "dw = pred_anchor_locs_numpy[:, 3::4] # dw\n",
    "\n",
    "# ctr_y = dy predicted by RPN * anchor_h + anchor_cy\n",
    "# ctr_x similar\n",
    "# h = exp(dh predicted by RPN) * anchor_h\n",
    "# w similar\n",
    "ctr_y = dy * anc_height[:, np.newaxis] + anc_ctr_y[:, np.newaxis]\n",
    "ctr_x = dx * anc_width[:, np.newaxis] + anc_ctr_x[:, np.newaxis]\n",
    "h = np.exp(dh) * anc_height[:, np.newaxis]\n",
    "w = np.exp(dw) * anc_width[:, np.newaxis]\n",
    "\n",
    "roi = np.zeros(pred_anchor_locs_numpy.shape, dtype=anchor_locs.dtype)\n",
    "roi[:, 0::4] = ctr_y - 0.5 * h\n",
    "roi[:, 1::4] = ctr_x - 0.5 * w\n",
    "roi[:, 2::4] = ctr_y + 0.5 * h\n",
    "roi[:, 3::4] = ctr_x + 0.5 * w\n",
    "\n",
    "# clip the predicted boxes to the image\n",
    "img_size = (800, 800) #Image size\n",
    "roi[:, slice(0, 4, 2)] = np.clip(roi[:, slice(0, 4, 2)], 0, img_size[0])\n",
    "roi[:, slice(1, 4, 2)] = np.clip(roi[:, slice(1, 4, 2)], 0, img_size[1])\n",
    "\n",
    "# Remove predicted boxes with either height or width < threshold.\n",
    "min_size=16\n",
    "hs = roi[:, 2] - roi[:, 0]\n",
    "ws = roi[:, 3] - roi[:, 1]\n",
    "keep = np.where((hs >= min_size) & (ws >= min_size))[0] #min_size=16\n",
    "\n",
    "roi = roi[keep, :]\n",
    "roi_old = roi\n",
    "score = objectness_score_numpy[keep]\n",
    "#print(keep.shape, roi.shape, score.shape)\n",
    "\n",
    "# Sort all (proposal, score) pairs by score from highest to lowest\n",
    "order = np.ravel(score).argsort()[::-1]\n",
    "#print(order.shape)\n",
    "\n",
    "#Take top pre_nms_topN (e.g. 12000 while training and 300 while testing)\n",
    "order = order[:n_train_pre_nms]\n",
    "roi = roi[order, :]\n",
    "\n",
    "# Take all the roi boxes [roi_array]\n",
    "y1 = roi_old[order, 0]\n",
    "x1 = roi_old[order, 1]\n",
    "y2 = roi_old[order, 2]\n",
    "x2 = roi_old[order, 3]\n",
    "# Find the areas of all the boxes [roi_area]\n",
    "areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\n",
    "#order = score.argsort()[::-1]\n",
    "keep = []\n",
    "while (order.size > 0):\n",
    "    i = order[0] #take the 1st elt in order and append to keep \n",
    "    keep.append(i)\n",
    "    xx1 = np.maximum(x1[0], x1[1:]) \n",
    "    yy1 = np.maximum(y1[0], y1[1:])\n",
    "    xx2 = np.minimum(x2[0], x2[1:])\n",
    "    yy2 = np.minimum(y2[0], y2[1:])\n",
    "    w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "    inter = w * h\n",
    "    ovr = inter / (areas[0] + areas[1:] - inter)\n",
    "    inds = np.where(ovr <= nms_thresh)[0] +1\n",
    "    order = order[inds]\n",
    "    x1 = x1[inds]\n",
    "    y1 = y1[inds]\n",
    "    x2 = x2[inds]\n",
    "    y2 = y2[inds]\n",
    "    areas = areas[inds]\n",
    "keep = keep[:n_train_post_nms] # while training/testing , use accordingly\n",
    "roi = roi_old[keep] # the final region proposals\n",
    "\n",
    "ious = box_iou(roi,bbox)    #find iou of roi with gt bbox\n",
    "\n",
    "# Find out which ground truth has high IoU for each region proposal, Also find the maximum IoU\n",
    "gt_assignment = ious.argmax(axis=1)\n",
    "max_iou = ious.max(axis=1)\n",
    "#print(gt_assignment)\n",
    "#print(max_iou)\n",
    "\n",
    "# Assign the labels to each proposal\n",
    "gt_roi_label = labels[gt_assignment]\n",
    "\n",
    "# Select the foreground rois as per the pos_iou_thesh and \n",
    "# n_sample x pos_ratio (128 x 0.25 = 32) foreground samples.\n",
    "pos_roi_per_image = 32 \n",
    "pos_index = np.where(max_iou >= pos_iou_thresh)[0]\n",
    "pos_roi_per_this_image = int(min(pos_roi_per_image, pos_index.size))\n",
    "if pos_index.size > 0:\n",
    "    pos_index = np.random.choice(\n",
    "        pos_index, size=pos_roi_per_this_image, replace=False)\n",
    "#print(pos_roi_per_this_image)\n",
    "#print(pos_index)\n",
    "\n",
    "# Similarly we do for negitive (background) region proposals\n",
    "neg_index = np.where((max_iou < neg_iou_thresh_hi) &\n",
    "                             (max_iou >= neg_iou_thresh_lo))[0]\n",
    "neg_roi_per_this_image = n_sample - pos_roi_per_this_image\n",
    "neg_roi_per_this_image = int(min(neg_roi_per_this_image, neg_index.size))\n",
    "if  neg_index.size > 0 :\n",
    "    neg_index = np.random.choice(\n",
    "        neg_index, size=neg_roi_per_this_image, replace=False)\n",
    "    \n",
    "\n",
    "# Now we gather positve samples index and negitive samples index, \n",
    "# their respective labels and region proposals\n",
    "\n",
    "keep_index = np.append(pos_index, neg_index)\n",
    "gt_roi_labels = gt_roi_label[keep_index]\n",
    "gt_roi_labels[pos_roi_per_this_image:] = 0  # negative labels --> 0\n",
    "sample_roi = roi[keep_index]\n",
    "#print(sample_roi.shape)\n",
    "\n",
    "# Pick the ground truth objects for these sample_roi and \n",
    "# later parameterize as we have done while assigning locations to anchor boxes in section 2.\n",
    "bbox_for_sampled_roi = bbox[gt_assignment[keep_index]]\n",
    "#print(bbox_for_sampled_roi.shape)\n",
    "\n",
    "height = sample_roi[:, 2] - sample_roi[:, 0]\n",
    "width = sample_roi[:, 3] - sample_roi[:, 1]\n",
    "ctr_y = sample_roi[:, 0] + 0.5 * height\n",
    "ctr_x = sample_roi[:, 1] + 0.5 * width\n",
    "\n",
    "base_height = bbox_for_sampled_roi[:, 2] - bbox_for_sampled_roi[:, 0]\n",
    "base_width = bbox_for_sampled_roi[:, 3] - bbox_for_sampled_roi[:, 1]\n",
    "base_ctr_y = bbox_for_sampled_roi[:, 0] + 0.5 * base_height\n",
    "base_ctr_x = bbox_for_sampled_roi[:, 1] + 0.5 * base_width\n",
    "\n",
    "eps = np.finfo(height.dtype).eps\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)\n",
    "gt_roi_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compact-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.array(sample_roi, dtype=np.float32)\n",
    "roi_indices = np.zeros((len(rois),), dtype=np.float32)\n",
    "\n",
    "#print(rois.shape, roi_indices.shape)\n",
    "\n",
    "indices_and_rois = np.concatenate([roi_indices[:, None], rois], axis=1)\n",
    "xy_indices_and_rois = indices_and_rois[:, [0, 2, 1, 4, 3]]\n",
    "indices_and_rois = xy_indices_and_rois\n",
    "#print(xy_indices_and_rois.shape)\n",
    "\n",
    "#roi pooling \n",
    "size = (7, 7)\n",
    "output = npx.roi_pooling(out_map,xy_indices_and_rois, size,1.0/16.0)\n",
    "kk = output.reshape(output.shape[0],-1)\n",
    "\n",
    "kk = roi_head_classifier(kk)\n",
    "roi_cls_loc = cls_loc(kk)\n",
    "roi_cls_score = score_l(kk)\n",
    "\n",
    "gt_roi_loc = np.array(gt_roi_locs)\n",
    "gt_roi_label = np.array(gt_roi_labels, dtype = np.float32)\n",
    "\n",
    "#loss2_1 start\n",
    "##roi_cls_loss = cross_entropy(roi_cls_score, gt_roi_label)\n",
    "ce_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "roi_cls_loss= ce_loss(roi_cls_score, gt_roi_label).mean()\n",
    "#loss2_1 over\n",
    "\n",
    "#regression ( loss2_2) start\n",
    "n_sample = roi_cls_loc.shape[0]\n",
    "roi_loc = roi_cls_loc.reshape(n_sample, -1,4)\n",
    "roi_loc = roi_loc[np.arange(0,n_sample),gt_roi_label]\n",
    "pos = (gt_roi_label > 0).reshape(-1,1)\n",
    "mask = np.ones((pos.shape[1],4), dtype= pos.dtype)\n",
    "mask = pos * mask\n",
    "mask_loc_preds = roi_loc[mask].reshape(-1, 4)\n",
    "mask_loc_targets = gt_roi_loc[mask].reshape(-1, 4)\n",
    "x = np.abs(mask_loc_targets - mask_loc_preds)\n",
    "roi_loc_loss = mxnet.nd.npx.smooth_l1(x).sum()\n",
    "\n",
    "#loss2_2 over\n",
    "# loss2 sum start\n",
    "roi_lambda = 10.\n",
    "roi_loss = roi_cls_loss + (roi_lambda * roi_loc_loss)\n",
    "#loss2 sum over\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decreased-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total loss \n",
    "total_loss = rpn_loss + roi_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "careful-category",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(57.394974)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-movie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-poland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-recommendation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-sentence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-rocket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-fifty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-inclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-novel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-reduction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-renewal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-problem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-facility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-horizontal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-woman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-worcester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-money",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-standing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-visibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-perfume",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-quilt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-column",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
